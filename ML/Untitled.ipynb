{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63b19ed6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Step 1: Load your CSV (no priority yet)\n",
    "df = pd.read_csv(\"Datasetprojpowerbi.csv\")\n",
    "\n",
    "# Step 2: Define keyword categories\n",
    "high_priority_keywords = [\"emergency\", \"harassment\", \"assault\", \"fire\", \"violence\", \"medical\", \"mental health\"]\n",
    "medium_priority_keywords = [\"wifi\", \"internet\", \"water\", \"electricity\", \"hostel\", \"fan\", \"ac\"]\n",
    "low_priority_keywords = [\"canteen\", \"menu\", \"food\", \"cleanliness\", \"noise\", \"bugs\"]\n",
    "\n",
    "# Step 3: Define a function to assign priority\n",
    "def match_keywords(complaint, keywords):\n",
    "    tokens = re.findall(r'\\b\\w+\\b', complaint.lower())\n",
    "    return any(any(k in word for word in tokens) for k in keywords)\n",
    "\n",
    "def assign_priority(complaint):\n",
    "    if match_keywords(complaint, high_priority_keywords):\n",
    "        return \"High\"\n",
    "    elif match_keywords(complaint, medium_priority_keywords):\n",
    "        return \"Medium\"\n",
    "    elif match_keywords(complaint, low_priority_keywords):\n",
    "        return \"Low\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "\n",
    "# Step 4: Apply the function to the dataset\n",
    "df['priority'] = df['Reports'].apply(assign_priority)\n",
    "\n",
    "\n",
    "# Step 5: Save the new dataset (optional)\n",
    "df.to_csv(\"labeled_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e97dce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2aae6018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Genre', 'Reports', 'Age', 'Gpa', 'Year', 'Count', 'Gender',\n",
      "       'Nationality', 'priority'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81129f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Step 1: Load your CSV (no priority yet)\n",
    "df = pd.read_csv(\"Datasetprojpowerbi.csv\")\n",
    "\n",
    "# Step 2: Define keyword categories\n",
    "high_priority_keywords = [\"emergency\", \"harassment\", \"assault\", \"fire\", \"violence\", \"medical\", \"mental health\"]\n",
    "medium_priority_keywords = [\"wifi\", \"internet\", \"water\", \"electricity\", \"hostel\", \"fan\", \"ac\"]\n",
    "low_priority_keywords = [\"canteen\", \"menu\", \"food\", \"cleanliness\", \"noise\", \"bugs\"]\n",
    "\n",
    "# Step 3: Define a function to assign priority\n",
    "def match_keywords(complaint, keywords):\n",
    "    tokens = re.findall(r'\\b\\w+\\b', complaint.lower())\n",
    "    return any(any(k in word for word in tokens) for k in keywords)\n",
    "\n",
    "def assign_priority(complaint):\n",
    "    if match_keywords(complaint, high_priority_keywords):\n",
    "        return \"High\"\n",
    "    elif match_keywords(complaint, medium_priority_keywords):\n",
    "        return \"Medium\"\n",
    "    elif match_keywords(complaint, low_priority_keywords):\n",
    "        return \"Low\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "\n",
    "# Step 4: Apply the function to the dataset\n",
    "df['priority'] = df['Reports'].apply(assign_priority)\n",
    "\n",
    "\n",
    "# Step 5: Save the new dataset (optional)\n",
    "df.to_csv(\"labeled_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61b3d7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Genre  \\\n",
      "0  Academic Support and Resources   \n",
      "1  Academic Support and Resources   \n",
      "2  Academic Support and Resources   \n",
      "3  Academic Support and Resources   \n",
      "4  Academic Support and Resources   \n",
      "\n",
      "                                             Reports  Age   Gpa  Year  Count  \\\n",
      "0  The limited access to research databases and m...   27  2.18     2      1   \n",
      "1  I'm having trouble finding the course material...   23  3.11     2      1   \n",
      "2  It's frustrating to have limited access to res...   20  3.68     2      1   \n",
      "3  I'm really struggling in one of my classes but...   20  1.30     2      1   \n",
      "4   I am really struggling with understanding the...   26  2.50     2      1   \n",
      "\n",
      "  Gender Nationality  \n",
      "0      M       Egypt  \n",
      "1      F       Egypt  \n",
      "2      F       Egypt  \n",
      "3      F       Egypt  \n",
      "4      F       Egypt  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"Datasetprojpowerbi.csv\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4363e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Genre  \\\n",
      "0  Academic Support and Resources   \n",
      "1  Academic Support and Resources   \n",
      "2  Academic Support and Resources   \n",
      "3  Academic Support and Resources   \n",
      "4  Academic Support and Resources   \n",
      "\n",
      "                                             Reports  Age   Gpa  Year  Count  \\\n",
      "0  The limited access to research databases and m...   27  2.18     2      1   \n",
      "1  I'm having trouble finding the course material...   23  3.11     2      1   \n",
      "2  It's frustrating to have limited access to res...   20  3.68     2      1   \n",
      "3  I'm really struggling in one of my classes but...   20  1.30     2      1   \n",
      "4   I am really struggling with understanding the...   26  2.50     2      1   \n",
      "\n",
      "  Gender Nationality  \n",
      "0      M       Egypt  \n",
      "1      F       Egypt  \n",
      "2      F       Egypt  \n",
      "3      F       Egypt  \n",
      "4      F       Egypt  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv(\"Datasetprojpowerbi.csv\")\n",
    "\n",
    "# Step 2: Show top rows to confirm\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eee9e834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meghashree v\\ComplainHub\\ML\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b22b6d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Priority column added and saved to labeled_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Step 3: Define keyword categories\n",
    "high_priority_keywords = [\"harassment\", \"violence\", \"fire\", \"emergency\", \"mental\", \"assault\", \"medical\", \"urgent\"]\n",
    "medium_priority_keywords = [\"wifi\", \"electricity\", \"food\", \"water\", \"bathroom\", \"hostel\", \"noise\", \"maintenance\"]\n",
    "low_priority_keywords = [\"menu\", \"taste\", \"dirty\", \"bugs\", \"fan\", \"decor\", \"chair\", \"boring\"]\n",
    "\n",
    "# Function to assign priority\n",
    "def assign_priority(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"Low\"\n",
    "    text = text.lower()\n",
    "    for word in high_priority_keywords:\n",
    "        if word in text:\n",
    "            return \"High\"\n",
    "    for word in medium_priority_keywords:\n",
    "        if word in text:\n",
    "            return \"Medium\"\n",
    "    for word in low_priority_keywords:\n",
    "        if word in text:\n",
    "            return \"Low\"\n",
    "    return \"Low\"  # default\n",
    "\n",
    "# Step 4: Apply to the 'Reports' column\n",
    "df['priority'] = df['Reports'].apply(assign_priority)\n",
    "\n",
    "# Step 5: Save to new file\n",
    "df.to_csv(\"labeled_dataset.csv\", index=False)\n",
    "print(\"✅ Priority column added and saved to labeled_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23a87294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        High       1.00      0.53      0.69        19\n",
      "         Low       0.91      1.00      0.96       171\n",
      "      Medium       1.00      0.36      0.53        11\n",
      "\n",
      "    accuracy                           0.92       201\n",
      "   macro avg       0.97      0.63      0.73       201\n",
      "weighted avg       0.93      0.92      0.91       201\n",
      "\n",
      "✅ Model and vectorizer saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "\n",
    "# Load the labeled dataset\n",
    "df = pd.read_csv(\"labeled_dataset.csv\")\n",
    "\n",
    "# Features and labels\n",
    "X = df[\"Reports\"]  # Complaint text\n",
    "y = df[\"priority\"]  # Priority label\n",
    "\n",
    "# Vectorize text using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save model and vectorizer\n",
    "with open(\"complaint_priority_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "with open(\"tfidf_vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "\n",
    "print(\"✅ Model and vectorizer saved!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36ee745a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Priority: Low\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the saved model and vectorizer\n",
    "with open(\"complaint_priority_model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "with open(\"tfidf_vectorizer.pkl\", \"rb\") as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "\n",
    "# Test with a new complaint\n",
    "new_complaint = \"need projector\"\n",
    "\n",
    "# Transform using vectorizer\n",
    "vectorized_complaint = vectorizer.transform([new_complaint])\n",
    "\n",
    "# Predict priority\n",
    "predicted_priority = model.predict(vectorized_complaint)\n",
    "\n",
    "print(f\"Predicted Priority: {predicted_priority[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27bb8888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\meghashree v\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3468: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import pickle\n",
    "\n",
    "# Load model and vectorizer\n",
    "with open(\"complaint_priority_model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "with open(\"tfidf_vectorizer.pkl\", \"rb\") as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict_priority():\n",
    "    data = request.get_json()\n",
    "    complaint = data.get('complaint', '')\n",
    "\n",
    "    if not complaint:\n",
    "        return jsonify({\"error\": \"Complaint is required\"}), 400\n",
    "\n",
    "    # Vectorize and predict\n",
    "    vectorized_complaint = vectorizer.transform([complaint])\n",
    "    predicted_priority = model.predict(vectorized_complaint)\n",
    "\n",
    "    return jsonify({\"priority\": predicted_priority[0]})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efafb287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
